%!TEX root = ../thesis.tex
\chapter{Introduction \label{ch:intro}} 
A fluid queue is a two-dimensional stochastic process \(\{\bs X(t)\} = \{(X(t),\varphi(t))\}_{t\geq0}\). The phase process, also known as the driving process, \(\{\varphi(t)\}_{t\geq0}\), is a continuous-time Markov chain (CTMC). The level process, \(\{X(t)\}_{t\geq0}\), is a real-valued, continuous, and piecewise linear. 

Stochastic fluid queues have found a variety of applications such as telecommunications (see \cite{anick1982} as a canonical application in this area), power systems \citep{hydro}, risk processes \citep{betal2005} and environmental modelling \citep{wurm2020}. Fluid queues are relatively well studied. Largely, the analysis of fluid queues falls into two categories, matrix-analytic methods \citep{ajr2005,ar2003,ar2004,bean2005b,bean2005,bot08,bean2009,dasilva2005,latouche2018}, and differential equation-based methods \citep{anick1982,kk1995,beanetal2019}. %For example, Ramaswami CITE, analysed fluid queues by mapping them to a quasi-birth-and-death process (QBD), after which they applied known matrix-analytic methods for QBDs to compute quantities of interest. Anick Mitra Sondhi CITE, analysed fluid queues using a more direct differential equation-based method. Since Ramaswami's CITE initial work, there has been significant developments in the analysis of fluid queues CITE and related algorithms CITE. 

More recently, \cite{bo2014} extended fluid queues to \emph{so-called} stochastic fluid-fluid queues. In a fluid-fluid queue there is a second level process, \(\{Y(t)\}_{t\geq0}\) which is itself driven by a fluid queue, \(\{(X(t),\varphi(t))\}_{t\geq0}\). The analysis,  \citep{bo2014}, is in principal similar to the matrix-analytic methods of \citep{bean2005}, and derives results about the second level process \(\{Y(t)\}_{t\geq0}\) in terms of the infinitesimal generator (a differential operator) of the fluid queue, \(\{(X(t),\varphi(t))\}_{t\geq0}\). For practical computation of the results of \cite{bo2014}, a matrix-discretisation of the infinitesimal generator of the fluid queue can be used. To this end, to date, two possible discretisation have been suggested. Taking a differential equations-based approach, \cite{beanetal2019} use the discontinuous Galerkin (DG) method to discretise this operator, while \cite{bo2013} take a stochastic modelling and matrix-analytic methods approach to approximate the fluid-queue by a quasi-birth-and-death (QBD) process. Both approaches are insightful and offer different tools and perspectives with which to analyse the resulting approximations. It turns out that the latter approach is a sub-class of the former; the QBD can be viewed as the simplest DG scheme where the operator is projected onto a basis of piecewise constant functions.

%A QBD can be viewed as a two-dimensional CTMC, \(\{(L(t),\varphi(t))\}_{t\geq0}\), where \(\{L(t)\}\) is the discrete level process, and \(\{\varphi(t)\}_{t\geq0}\) is the phase process. The level process \(\{L(t)\}\) is skip free, meaning that, given the process is at level \(L(t)=\ell\), is may only jump to \(\ell+1\) or \(\ell-1\) at jump epochs. The sojourn time of \(\{L(t)\}\) in a given level follows a phase-type distribution 

In the context of approximating fluid queues, one advantage of the QBD discretisation and, equivalently, DG schemes with constant basis functions, is that they guarantee probabilities computed from the approximation are positive \citep[Section 3.3]{koltai2011}, see also \citep{nodalDGBook} and references therein. One justification for the positivity preserving property is from the interpretation of the discretisation as a stochastic process thereby ensuring positivity. For higher order DG schemes there is no such interpretation. Moreover, higher-order DG approximation schemes may produce negative, or highly oscillatory solutions, particularly when discontinuities or steep gradients are present. Methods to navigate the problem of negative or highly oscillatory solutions have been developed, such as slope limiters, and filtering (see \citep[Section 6.5]{nodalDGBook} and references therein). Slope limiting effectively alters the discretised operator in regions where oscillations are detected and lowers the order of the approximation in theses regions. Filtering is a post-hoc method which looks to recover an accurate solution, given an oscillatory approximation. 

\section{Fluid queues}
A fluid queue is a two-dimensional stochastic process \(\{\bs X(t)\} = \{(X(t),\varphi(t))\}_{t\geq0}\) where \(\{\varphi(t)\}_{t\geq0}\) is known as the phase or driving process, and \(\{X(t)\}_{t\geq0}\) is known as the level process or buffer. The phase process \(\{\varphi(t)\}_{t\geq0}\), is an irreducible continuous-time Markov chain (CTMC) with finite state space, which we we assume to be \(\mathcal S=\{1,2,\dots,N\}\) without loss of generality, and infinitesimal generator \(\bs T= [T_{ij}]_{i,j\in\mathcal S}\). We assume that \(\bs T\) is \emph{conservative}. Associated with states \(i\in\mathcal S\) are real-valued \emph{rates} \(c_i\in\mathbb R\). 

Partition the state space \(\calS\) into \(\calS_+ = \{i\in\calS\mid c_i>0\}\), \(\calS_- = \{i\in\calS\mid c_i<0\}\) and \(\calS_0 = \{i\in\calS\mid c_i=0\}\). We assume, without loss of generality, that the generator \(\bs T\) is partitioned into sub-matrices 
\[\bs T = \left[\begin{array}{ccc}\bs T_{++} & \bs T_{+-} & \bs T_{+0} \\ \bs T_{-+} & \bs T_{--} & \bs T_{-0} \\ \bs T_{0+} & \bs T_{0-} & \bs T_{00}  \end{array}\right],\]
where \(\bs T_{mn} = [T_{ij}]_{i\in\mathcal S_m, j\in\mathcal S_n}\), \(m,n\in\{+,-,0\}\). Also define the diagonal matrices 
\begin{align*}
	\bs C &= \left[\begin{array}{ccc} \bs C_+ && \\ &\bs C_-& \\ && \bs 0\end{array}\right], && \bs C_+ = diag(c_i,i\in\calS_+), && \bs C_- = diag(|c_i|,i\in\calS_-),
\end{align*}
where \(diag(a_i,i\in\mathcal I)\) denotes a diagonal matrix with entries \(a_i\) down the diagonal. 

When no boundary conditions are imposed, the level process is given by 
\[X(t) = X(0) + \int_{s=0}^t c_{\varphi(s)}\wrt s.\]
Sample paths of \(\{X(t)\}\) are continuous and piecewise linear, with \(\cfrac{\wrt }{\wrt t} X(t) = c_\varphi(t)\), when \(X(t)\) is differentiable. Given sample paths of \(\{\varphi(t)\}\), then \(\{X(t)\}\) is deterministic, and in this sense, \(\{\varphi(t)\}\) is the only stochastic element of the fluid queue. 

Often, boundary conditions are imposed. Here, we consider a mixture of \emph{regulated} and \emph{reflecting} boundary conditions. Upon hitting a boundary we suppose that, with probability \(p_{ij},\,i,j\in\mathcal S\), the phase process instantaneously transitions from phase \(i\) to phase \(j\) (note that we might have \(i=j\) i.e.~no transition). At a lower boundary, if \(j\in\calS_0\cup\calS_-\), then \(\cfrac{\wrt}{\wrt t} X(t) = 0\), and the phase process continues to evolve according to the sub-generator 
\[\left[\begin{array}{cc} \bs T_{--} & \bs T_{-0} \\ \bs T_{0-} & \bs T_{00}  \end{array}\right],\]
until such a time that \(\varphi(t)\) transitions to a phase \(k\in\calS_+\), at which time \(X(t)\) leaves the boundary. Similarly, at an upper boundary if \(j\in\calS_0\cup\calS_+\), then \(\cfrac{\wrt}{\wrt t} X(t) = 0\) and the phase process continues to evolve according to the sub-generator 
\[\left[\begin{array}{cc} \bs T_{++} & \bs T_{+0} \\ \bs T_{0+} & \bs T_{00}  \end{array}\right],\]
until such a time that \(\varphi(t)\) transitions to a phase \(k\in\calS_-\) at which time \(X(t)\) leaves the boundary. Without loss of generality, we assume the lower and upper boundaries (when present) are at \(x=0\) and \(x=M>0\), respectively.

In summary, the evolution of the level can be expressed as 
\[\cfrac{\wrt}{\wrt t} X(t) = \begin{cases} c_{\varphi(t)}, & \mbox{ if } X(t)>0, \\ \max\{0,c_{\varphi(t)}\}, & \mbox{ if } X(t)=0, \\ \min\{0,c_{\varphi(t)}\}, & \mbox{ if } X(t)=M.  \end{cases}\]

Let \(\bs f(x,t) = \vligne{f_i(x,t)}_{i\in\calS}\) be a row-vector function where \(f_i(x,t)\) is the density of \(\mathbb P(X(t)\leq x, \varphi(t) = i)\), assuming it exists. When a differentiable density exists, the system of partial differential equation which describes the evolution of the densities \(\bs f(x,t)\) is 
\begin{equation}
	\cfrac{\partial}{\partial t} \bs f(x,t) = \bs f(x,t)\bs T - \cfrac{\partial}{\partial x}\bs f(x,t)\bs C.\label{eqn: pde}
\end{equation}
The initial condition is the initial distribution of the fluid queue, \(f_i(x,0)\). Often a differentiable density function does not exist and therefore the partial differential equation (\ref{eqn: pde}) is not well-defined. For example, for a fluid queue with a regulated boundary, if the initial distribution of the fluid queue is a point mass at any point \(x_0\geq 0\) and in phase \(i\in\calS_+\cup\calS_0\), then a density function \(f_i(x,t)\) will not exist for any finite \(t\). Specifically, a point mass will persist along the ray \(x_0+c_it\), \(t\geq 0\). In such situations, it is the \emph{weak solution} to (\ref{eqn: pde}) that we seek. A weak solution satisfies
\begin{equation}
	-\int_x\int_t \bs f(x,t)\cfrac{\partial}{\partial t} \bs \psi(x,t)\wrt t \wrt x= \int_{x}\int_t\bs f(x,t)\bs T\bs \psi(x,t)\wrt t \wrt x + \int_x\int_t\bs f(x,t)\bs C \cfrac{\partial}{\partial x} \bs psi(x,t)\wrt t \wrt x,\label{eqn: weak pde}
\end{equation}
for every vector of test functions, \(\bs \psi(x,t)\), wich are smooth and have compact support.

Boundary conditions may also be imposed on (\ref{eqn: pde}). 

Discretisation methods approximate the operator on the right-hand side of (\ref{eqn: pde}) by a matrix, in our case, by the generator of a QBD-RAP. 

\section{Matrix-exponential distributions}
Here we recount some facts about matrix exponential distributions. See \citep{MEinAP} for a more detailed exposition. A random variable, \(Z\), is said to have a matrix-exponential distribution if it has a distribution function of the form \(1-\bs \alpha e^{\bs Sx}(-\bs S)^{-1}\bs s\), where \(\bs \alpha\) is a \(1\times p\) \emph{initial vector}, \(\bs S\) a \(p\times p\) matrix, and \(\bs s\) a \(p\times 1\) \emph{closing vector}, and \(\displaystyle e^{\bs S x} := \sum_{n=0}^\infty \cfrac{\left(\bs Sx\right)^n}{n!}\) is the matrix exponential. The density function of \(Z\) is given by \(f_Z(x) = \bs\alpha e^{\bs S x}\bs s\). The only restrictions on the parameters \((\bs \alpha, \bs S, \bs s)\) are that \(\bs \alpha e^{\bs S x} \bs s\) be a valid density function, i.e.~\(\bs \alpha e^{\bs S x} \bs s\geq 0,\) for all \(x\geq 0\) and \(\lim_{x\to\infty} 1-\bs \alpha e^{\bs Sx}(-\bs S)^{-1}\bs s = 1.\) There is the possibility of an \emph{atom} (a point mass) at 0, but here we do not consider this possibility. These condition that \(\bs \alpha e^{\bs Sx}\bs s\) be a valid density imposes some properties on representations \((\bs \alpha, \bs S, \bs s)\). However, in general there is no way to determine whether, given a triplet \((\bs \alpha, \bs S, \bs s)\) whether it is a representation of a matrix-exponential distribution, or not. Nonetheless, some properties of a triplet \((\bs \alpha, \bs S, \bs s)\) are known, such as the following, which is used in the characterisation of QBD-RAPs. 
\begin{thm}[Theorem 4.1.3, \cite{MEinAP}]
	The density function of a matrix-exponential distribution with representation \((\bs\alpha, \bs S, \bs s)\) can be expressed in terms of real-valued constants as 
	\begin{align}
		\psi(x)&=\sum_{j=1}^{m_1} \sum_{k=1}^{p_j} c_{jk} \cfrac{x^{k-1}}{(k-1)!} e^{\mu_jx} + \sum_{j=1}^{m+2}\sum_{k=1}^{q_j} d_{jk}\cfrac{x^{k-1}}{(k-1)!}e^{\eta_jx}\cos(\sigma_jx) \nonumber 
		\\&\quad{}+ \sum_{j=1}^{m_2}\sum_{k=1}^{q_j}e_{jk}\cfrac{x^{k-1}}{(k-1)!}e^{\eta_jx}\sin(\sigma_jx), \label{eqn: spec}
	\end{align}
	for integers \(m_1,\,m_2,\,p_j,\) and \(q_j\) and some real constants \(c_{jk},\,d_{jk},\,e_{jk},\,\mu_j,\,\eta_j,\) and \(\sigma_j\). Here \(\mu_j,\, j=1,\dots,m_1\) are the real eigenvalues of \(\bs S\), while \(\eta_j+i\sigma_j, \, \eta_j-i\sigma_j,\, j=1,\dots,m_2\) denote its complex eigenvalues, which come in conjugate pairs. Thus \(m_1+2m_2\) is the total number of eigenvalues, while the dimension of the representation is given by \(\displaystyle p=\sum_{j=1}^{m+1}p_j + 2\sum_{j=1}^{m_2}q_j\). 
\end{thm}
\begin{thm}[Theorem 4.1.4, \cite{MEinAP}]\label{thm: 4.1.4}
	Consider the nonvanishing terms of the matrix exponential density (\ref{eqn: spec}), \emph{i.e.}, the terms for which \(c_{jk}=0,\,d_{jk} =0,\) or \(e_{jk}=0\). Among the corresponding eigenvalues \(\lambda_j\), there is a real dominating eigenvalue \(\kappa\), say. That is, \(\kappa\) is real, \(\kappa \geq Re(\lambda_j)\) for all \(j\), and the multiplicity of \(\kappa\) is at least the multiplicity of every other eigenvalue with real part \(\kappa\).
\end{thm}
\begin{cor}[Corollary 4.1.5, \cite{MEinAP}]
If \((\bs \alpha, \bs S, \bs s)\) is a representation for a matrix-exponential distribution, then \(\bs S\) has a real dominating eigenvalues.
\end{cor}
\begin{thm}[Theorem 4.1.6, \cite{MEinAP}]
	Let \(Z\) be a matrix-exponentially distributed random variable with density (\ref{eqn: spec}). Then the dominant real eigenvalue \(\kappa\) of Theorem~\ref{thm: 4.1.4} is strictly negative. 
\end{thm}
We define \(dev(\bs S)\) to be the real dominating eigenvalue of \(\bs S\), that is \(dev(\bs S)=\kappa\) in Theorem~\ref{thm: 4.1.4}.

The class of matrix-exponential distribution is characterised as the class of probability distributions which have a rational Laplace transform. That is, \(\displaystyle \int_{x=0}^\infty e^{-\lambda x}\bs \alpha e^{\bs S x}\bs s \wrt x\) is a ratio of two polynomial functions in \(\lambda\). Matrix exponential distributions are an extension of Phase-type distributions, where for the latter, \(\bs S\) must be a sub-generator matrix of a CTMC, \(\bs s = -\bs S\bs e\) where \(\bs e\) is a \(1\times p\) vector of ones, and \(\bs \alpha\) is a discrete probability distribution.  

A \emph{representation} of a matrix exponential distribution is a triplet \((\bs \alpha, \bs S, \bs s)\), and we write \(Z\sim ME(\bs \alpha, \bs S, \bs s)\) to denote that \(Z\) has a matrix-exponential distribution with this representation. The order of the representation is the dimension of the square matrix \(\bs S\), i.e.~if \(\bs S\) is \(p\times p\), then the matrix exponential distribution is said to be of order \(p\). Representations of matrix-exponential distributions are not unique \citep{MEinAP}. A representation is called \emph{minimal} when \(\bs S\) has the smallest possible dimension. Throughout this work, we assume that the representation of any matrix exponential distribution is minimal. Let \(\bs e_i\) be a vector with a 1 in the \(i\)th position and zeros elsewhere. We assume that \(\bs s = -\bs S\bs e\), and that \((\bs e_i,\bs S,\bs s)\) for \(i=1,\dots,p\) are representations of matrix exponential distributions. It is always possible to find such a representation \cite[Theorem 4.5.17, Corollary 4.5.18]{MEinAP}. As such, we abbreviate our notation \(Z\sim ME(\bs \alpha, \bs S, \bs s)\) to \(Z\sim ME(\bs \alpha, \bs S)\). Further, given \(\bs s=-\bs S\bs e\) then observe that  \(\displaystyle \int_{x=0}^\infty e^{\bs S x} \bs s\wrt x = (-\bs S)^{-1}\bs s= \bs e\). 

For a given \(p\times p\) matrix \(\bs S\), denote by \(\mathcal A\subset \mathbb R^p\) the space of all possible vectors \(\bs a\) such that \((\bs a, \bs S)\) is a valid representation of a matrix exponential distribution. %By CITE it is known that \(\mathcal A\) is a closed, bounded, convex, affine subspace of \(\mathbb R^p\). 



%\section{Rational arrival processes}
%Let \(N\) be a simple point process, with event time \(Y_0=0<Y_1<Y_2<\cdot\). Let \(\{N(t)\}_{t\geq0}\) be the right-continuous counting process associated with \(N\); \(N(t)\) returns the number of events by time \(t\). Denote by \(f_{N,n}(y_1,\dots,y_n)\) the joint density of \(Y_1, Y_2-Y_1, \dots,Y_n-Y_{n-1}\), the first \(n\) inter-arrival times. For a matrix \(\bs B\) let \(dev(\bs B)\) denote the dominant eigenvalue of \(\bs B\) (the one with maximal real part). Theorem 1.1 of Asmussen and Bladt CITE states that the point process \(N\) is a RAP if there exists matrices \(\bs S\), \(\bs D\), a row vector \(\bs\alpha\), and a column vector \(\bs s\) such that \(dev(\bs S)<1\), \(dev(\bs S+\bs D)=0\), \((\bs S+\bs D)\bs e=0,\) and 
%\[f_{N,n}(y_1,\dots,y_n) = \bs \alpha e^{\bs Sy_1} \bs D e^{\bs Sy_1} \bs D \dots e^{\bs Sy_n} \bs s.\]
%Here \(\bs s\) can be taken to be \(\bs D e\). The \(n\)th inter-arrival, \(T_n-T_{n-1}\), has a matrix exponential distribution with density \(\bs \alpha(-\bs S\bs D )^{n-1}e^{\bs S x_n}\bs s\). Denote such a process \(N \sim RAP(\bs \alpha, \bs S, \bs D)\). 
%
%Asmussen and Bladt CITE, Corollary 2.2, show that associated with the RAP is a row-vector-valued \emph{orbit} process, \(\{\bs A(t)\}_{t\geq0},\), 
%\[\bs A(t) = \cfrac{\bs \alpha\left( \prod_{i=1}^{N(t)} e^{\bs S(Y_{i}-Y_{i-1})}\bs S\right)e^{\bs S t-Y_{N(t)}}}{\bs \alpha\left( \prod_{i=1}^{N(t)} e^{\bs S(Y_{i}-Y_{i-1})}\bs S\right)e^{\bs S( t-Y_{N(t)})}\bs e}.\]
%Thus, \(\{\bs A(t)\}\) is a piecewise-deterministic Markov process where, in between jumps \(\{\bs A(t)\}\) according to 
%\[\bs A(t) = \cfrac{\bs A(Y_{N(t)}^-)e^{\bs S(t-Y_{N(t)})}}{\bs A(Y_{N(t)}^-)e^{\bs S(t-Y_{N(t)})}\bs e},\]
%where \(\bs A(Y_{N(t)}^-) = \lim_{u\to 0^+}\bs A(Y_{N(t)}-u)\). The process \(\{\bs A(t)\}\) jumps at event times of \(N\). At time \(t\) the intensity with which \(\{\bs A(t)\}\) has a jump is \(\bs A(t) \bs D\bs e\), and upon a jump at time \(t\), the new position of the orbit is \(\bs A(t) = \bs A(t^-) \bs D/\bs A(t^-) \bs D\bs e\). 
%
%RAPs are an extension of Markovian arrival processes (MAPs) to include matrix-exponential inter-arrival times. For MAPs, the vector \(\bs A(t)\) is a vector of posterior probabilities of a continuous-time Markov chain. 
%
%Intuitively, \(\bs A(t)\) encodes all of the information about the jump times of the RAP up to time \(t\). Let \(\mathcal F_{t}\) be the \(\sigma\)-algebra generated by \(N(u), u\in[0,t]\). Then \(N\mid \mathcal F_t \equiv N\mid \bs A(t) \sim ME(\bs A(t), \bs S, \bs S)\). In words, the future of the point process after time \(t\) given all of the information about the process up to and including time \(t\), is distributed as a RAP with initial vector \(\bs A(t)\). 

\section{QBD-RAPs}\label{sec: qbd-rap}
As RAPs are an extension of Markovian arrival processes to include matrix-exponential inter-arrival times, QBD-RAPs are extensions of QBDs to include matrix-exponential times between level changes. To define a QBD-RAP we first need a Batch (Marked) RAP. 

Let \(\mathscr K\subset \mathbb Z\) be a set of \emph{marks}. Let \(N\) be a point process, and \(Y_0=0<Y_1<Y_2\cdots\) be event times of \(N\). Let \(\{N(t)\}\) be the counting process associated with \(N\) such that \(N(t)\) returns the number of events by time \(t\). Associated with the \(n\)th event is a mark \(M_n\). For \(i\in\mathscr K\), let \(N_i\) be simple point processes associated with events with marks of type \(i\) only, and let \(\{N_i(t)\}_{t\geq 0}\) be the associated counting processes of events of mark \(i\). For a matrix \(\bs B\) let \(dev(\bs B)\) denote the real part of the dominant eigenvalue of \(\bs B\) (the one with maximal real part). Denote by \(f_{N,n}(y_1,m_1,y_2,m_2,\dots,y_n,m_n)\) the joint density, probability mass function of the first \(n\) inter-arrival times, \(Y_1,Y_2-Y_1,\dots,Y_n-Y_{n-1}\), and the associated marks \(M_n\). From Bean and Nielsen \cite[Theorem 1]{bn2010} we have the following. 
\begin{thm}
A process \(N\) is a Marked RAP if there exist matrices \(\bs S\), \(\bs D_i,\,i\in\mathscr K\), and a row vector \(\bs \alpha\) such that \(dev(\bs S)<0\), \(dev(\bs S+\bs D)=0\), \((\bs S+\bs D)\bs e = 0\), \(\bs D = \sum_{i\in\mathscr K} \bs D_i\), and 
\begin{align}f_{N,n}(y_1,m_1,y_2,m_2,\dots,y_n,m_n) = \bs \alpha e^{\bs S y_1}\bs D_{m_1} e^{\bs S y_2} \bs D_{m_2}\dots e^{\bs S y_n} \bs D_{m_n}\bs e.\label{eqn: brap}\end{align}
Conversely, if a point process has the property (\ref{eqn: brap}) then it is a Marked RAP.
\end{thm}

Denote such a process \(N\sim BRAP(\bs \alpha, \bs S, \bs D_i,\,i\in\mathscr K).\)

Also from \cite{bn2010}, associated with a Marked RAP is a row-vector-valued \emph{orbit} process, \(\{\bs A(t)\}_{t\geq0},\)
\[\bs A(t) = \cfrac{\bs \alpha\left( \prod\limits_{i=1}^{N(t)} e^{\bs S(Y_{i}-Y_{i-1})}\bs D_{M_i}\right)e^{\bs S (t-Y_{N(t)})}}{\bs \alpha\left( \prod\limits_{i=1}^{N(t)} e^{\bs S(Y_{i}-Y_{i-1})}\bs D_{M_i}\right)e^{\bs S( t-Y_{N(t)})}\bs e}.\]
Thus, \(\{\bs A(t)\}\) is a piecewise-deterministic Markov process where, in between events \(\{\bs A(t)\}\) evolves deterministically according to 
\[\bs A(t) = \cfrac{\bs A(Y_{N(t)}^-)e^{\bs S(t-Y_{N(t)})}}{\bs A(Y_{N(t)}^-)e^{\bs S(t-Y_{N(t)})}\bs e},\]
where \(\bs A(Y_{N(t)}^-) = \lim_{u\to 0^+}\bs A(Y_{N(t)}-u)\). The process \(\{\bs A(t)\}\) "jumps" at event times of \(N\) (the process may not always jump at these times, but typically the dynamics change discontinuously at this point). At time \(t\) the intensity with which \(\{\bs A(t)\}\) has a jump is \(\bs A(t) \bs D\bs e\). Upon an event the event is associated with mark \(i\) with probability \(\bs A(t) \bs D_i\bs e/\bs A(t) \bs D\bs e\). Upon on an event at time \(t\) with mark \(i\), the new position of the orbit is \(\bs A(t) = \bs A(t^-) \bs D_i/\bs A(t^-) \bs D_i\bs e\). It is important to note that the jumps of the orbit process are \emph{linear} transformations of the orbit process immediately before the time of the jump. 

Marked RAPs are an extension of Marked Markovian arrival processes to include matrix-exponential inter-arrival times. For Marked MAPs, the vector \(\bs A(t)\) is a vector of posterior probabilities of a continuous-time Markov chain. 

Intuitively, \(\bs A(t)\) encodes all of the information about the event times of the Marked RAP and associated marks up to time \(t\) that is needed to determine the future behaviour of the point process. Let \(\mathcal F_{t}\) be the \(\sigma\)-algebra generated by \(N(u), u\in[0,t]\). Then \(N\mid \mathcal F_t \equiv N\mid \bs A(t) \sim BRAP(\bs A(t), \bs S, \bs D_i,i\in\mathscr K)\). In words, the future of the point process after time \(t\) given all of the information about the process up to and including time \(t\), is distributed as a Marked RAP with initial vector \(\bs A(t)\). 

Now consider a Marked RAP, \(N\sim BRAP(\bs \alpha, \bs S, \bs D_i,\,i\in\{-1,0,+1\}).\) The process \(\{(L(t),\bs A(t))\}_{t\geq0}\) formed by letting \(L(t) = N_{+1}(t) - N_{-1}(t)\) is a QBD-RAP. 


